{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Assignment3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "MXpCf68lW7eg",
        "_FO2RelRXDhc",
        "oB4cP0zigztk",
        "nxGrCkY2grXK",
        "nX3bMk8vgjCg",
        "PzglbAEWgdkX",
        "eqUOQ86Nf8Kr",
        "5I_vU7-Rf4Ar",
        "JVBHyEpYATKR",
        "HPnn4m3Fg6WY",
        "HsYMPjkIhB3B",
        "f79BleNNgJTe",
        "KHO1Q-r_gOq3",
        "dubHhha3gE7J",
        "OeDBnl1gJSzl",
        "SpW-lDYaACqD",
        "8J4yMOmoJfrD",
        "niOvGRJJJl1z"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abisubramanya27/CS6910_Assignment3/blob/master/src/Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXpCf68lW7eg"
      },
      "source": [
        "# Downloading dataset and unzipping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anLHOjMmcDNp",
        "outputId": "48efbd17-f297-49ad-ce5f-77cff7aba993"
      },
      "source": [
        "# Downloading dakshina dataset\n",
        "!yes | wget \"https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-14 05:50:17--  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.79.128, 108.177.119.128, 108.177.126.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.79.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2008340480 (1.9G) [application/x-tar]\n",
            "Saving to: ‘dakshina_dataset_v1.0.tar’\n",
            "\n",
            "dakshina_dataset_v1 100%[===================>]   1.87G   107MB/s    in 21s     \n",
            "\n",
            "2021-05-14 05:50:39 (91.6 MB/s) - ‘dakshina_dataset_v1.0.tar’ saved [2008340480/2008340480]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8z7gFejcpWM"
      },
      "source": [
        "# Unzipping dataset\n",
        "!yes | tar xopf dakshina_dataset_v1.0.tar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6Ixguaue_fq",
        "outputId": "40b4b311-14ce-41c2-f8e6-a212e655d152"
      },
      "source": [
        "!ls dakshina_dataset_v1.0/hi/lexicons"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hi.translit.sampled.dev.tsv   hi.translit.sampled.train.tsv\n",
            "hi.translit.sampled.test.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FO2RelRXDhc"
      },
      "source": [
        "# Reading and processing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrQotNMVPnSb"
      },
      "source": [
        "START_CHAR = '\\t'\n",
        "END_CHAR = '\\n'\n",
        "BLANK_CHAR = ' '"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-xkKp8jY8Q9"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def read_data(data_path, characters = False):\n",
        "    # Returns the (input, output) pair from the dataset\n",
        "    # If characters == True, the input/output sample would be in the form list of characters, else as string\n",
        "\n",
        "    with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        lines = [line.split(\"\\t\") for line in f.read().split(\"\\n\") if line != '']\n",
        "    \n",
        "    input, target = [val[1] for val in lines], [val[0] for val in lines]\n",
        "    if characters:\n",
        "        input, target = [list(inp_str) for inp_str in input], [list(tar_str) for tar_str in target]\n",
        "    return input, target\n",
        "\n",
        "\n",
        "def process_data(input, enc_timesteps, input_char_enc, target = None, dec_timesteps = None, target_char_enc = None):\n",
        "    # Returns the input and target data in a form needed by the Keras embedding layer (i.e) \n",
        "    # decoder_input & encoder_input -- (None, timesteps) where each character is encoded by an integer\n",
        "    # decoder_output -- (None, timesteps, vocabulary size) where the last dimension is the one-hot encoding\n",
        "\n",
        "    # BLANK_CHAR -- space (equivalent to no meaningful input / blank input)\n",
        "    encoder_input = np.array([[input_char_enc[ch] for ch in string] + [input_char_enc[BLANK_CHAR]] * (enc_timesteps - len(string)) for string in input])\n",
        "\n",
        "    decoder_input, decoder_target = None, None\n",
        "    if target is not None and dec_timesteps is not None and target_char_enc is not None:\n",
        "        # START_CHAR -- start of sequence, END_CHAR -- end of sequence\n",
        "        decoder_input = np.array([[target_char_enc[START_CHAR]] + [target_char_enc[ch] for ch in string] + [target_char_enc[END_CHAR]] \n",
        "                                    + [target_char_enc[BLANK_CHAR]] * (dec_timesteps - len(string) - 2) for string in target])\n",
        "        decoder_target = np.zeros((decoder_input.shape[0], dec_timesteps, len(target_char_enc)), dtype='float32')\n",
        "\n",
        "        for i in range(decoder_input.shape[0]):\n",
        "            for t, char_ind in enumerate(decoder_input[i]):\n",
        "                if t > 0:\n",
        "                    decoder_target[i,t-1,char_ind] = 1.0\n",
        "            decoder_target[i,t:,target_char_enc[BLANK_CHAR]] = 1.0\n",
        "\n",
        "    return encoder_input, decoder_input, decoder_target\n",
        "\n",
        "\n",
        "def encode_decode_characters(train_input, train_target, val_input, val_target):\n",
        "    # Returns the encoding for characters to integer (as a dictionary) and decoding for integers to characters (as a list) for input and target data\n",
        "\n",
        "    # Encoding and decoding of input vocabulary\n",
        "    input_char_enc = {}\n",
        "    input_char_dec = []\n",
        "    max_encoder_seq_length = 1\n",
        "    for string in train_input + val_input:\n",
        "        max_encoder_seq_length = max(max_encoder_seq_length, len(string))\n",
        "        for char in string:\n",
        "            if char not in input_char_enc:\n",
        "                input_char_enc[char] = len(input_char_dec)\n",
        "                input_char_dec.append(char)\n",
        "    if BLANK_CHAR not in input_char_enc:\n",
        "        input_char_enc[BLANK_CHAR] = len(input_char_dec)\n",
        "        input_char_dec.append(BLANK_CHAR)\n",
        "\n",
        "    # Encoding and decoding of target vocabulary\n",
        "    target_char_enc = {}\n",
        "    target_char_dec = []\n",
        "    target_char_enc[START_CHAR] = len(target_char_dec)\n",
        "    target_char_dec.append(START_CHAR)\n",
        "    max_decoder_seq_length = 1\n",
        "    for string in train_target + val_target:\n",
        "        max_decoder_seq_length = max(max_decoder_seq_length, len(string)+2)\n",
        "        for char in string:\n",
        "            if char not in target_char_enc:\n",
        "                target_char_enc[char] = len(target_char_dec)\n",
        "                target_char_dec.append(char)\n",
        "    target_char_enc[END_CHAR] = len(target_char_dec)\n",
        "    target_char_dec.append(END_CHAR)\n",
        "    if ' ' not in target_char_enc:\n",
        "        target_char_enc[BLANK_CHAR] = len(target_char_dec)\n",
        "        target_char_dec.append(BLANK_CHAR)\n",
        "\n",
        "    print(\"Number of training samples:\", len(train_input))\n",
        "    print(\"Number of validation samples:\", len(val_input))\n",
        "    print(\"Number of unique input tokens:\", len(input_char_dec))\n",
        "    print(\"Number of unique output tokens:\", len(target_char_dec))\n",
        "    print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "    print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
        "\n",
        "    return input_char_enc, input_char_dec, target_char_enc, target_char_dec, max_encoder_seq_length, max_decoder_seq_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97ou-pxE9gCQ",
        "outputId": "a8f35c7b-4cd0-46cc-8fcc-26b200675f06"
      },
      "source": [
        "input_char_enc = {}\n",
        "input_char_dec = []\n",
        "target_char_enc = {}\n",
        "target_char_dec = []\n",
        "max_encoder_seq_length = 0\n",
        "max_decoder_seq_length = 0\n",
        "\n",
        "# Reading training, validation and test data\n",
        "train_inp, train_out = read_data('./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv')\n",
        "val_inp, val_out = read_data('./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv')\n",
        "test_inp, test_out = read_data('./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv')\n",
        "# Assigning encoding and decoding for input and target characters\n",
        "input_char_enc, input_char_dec, target_char_enc, target_char_dec, max_encoder_seq_length, max_decoder_seq_length = encode_decode_characters(\n",
        "    train_inp, train_out, val_inp, val_out)\n",
        "\n",
        "# Assigning training, validation and test encoder input, decoder input, decoder output\n",
        "train_enc_input, train_dec_input, train_dec_target = process_data(train_inp, max_encoder_seq_length, input_char_enc, train_out, \n",
        "                                                                  max_decoder_seq_length, target_char_enc)\n",
        "val_enc_input, val_dec_input, val_dec_target = process_data(val_inp, max_encoder_seq_length, input_char_enc, val_out, \n",
        "                                                            max_decoder_seq_length, target_char_enc)\n",
        "test_enc_input, test_dec_input, test_dec_target = process_data(test_inp, max_encoder_seq_length, input_char_enc, test_out, \n",
        "                                                               max_decoder_seq_length, target_char_enc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training samples: 44204\n",
            "Number of validation samples: 4358\n",
            "Number of unique input tokens: 27\n",
            "Number of unique output tokens: 66\n",
            "Max sequence length for inputs: 20\n",
            "Max sequence length for outputs: 21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQd3bva5ha27"
      },
      "source": [
        "# Seq2Seq Model (without Attention)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB4cP0zigztk"
      },
      "source": [
        "### Creating model (without attention)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8jvETu5Ga6g"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "def create_model(encoder_vocab_size, decoder_vocab_size, inp_emb_size=64, no_enc_layers=1, no_dec_layers=1, \n",
        "                 hid_layer_size=64, cell_type='LSTM', dropout=0, r_dropout=0, cell_activation='tanh'):\n",
        "    '''\n",
        "    Function to create a seq2seq model without attention.\n",
        "    Arguments :\n",
        "        encoder_vocab_size -- (int) number of characters in input vocabulary\n",
        "        decoder_vocab_size -- (int) number of characters in output vocabulary\n",
        "        inp_emb_size -- (int, default : 64) size of input embedding layer for encoder and decoder\n",
        "        no_enc_layers -- (int, default : 1) number of layers of cell to stack in encoder\n",
        "        no_dec_layers -- (int, default : 1) number of layers of cell to stack in decoder\n",
        "        hid_layer_size -- (int, default : 64) size of hidden layer of the encoder and decoder cells\n",
        "        cell_type -- (string, default : 'LSTM') type of cell used in encoder and decoder (possible values : 'LSTM', 'GRU', 'RNN')\n",
        "        dropout -- (float, default : 0.0) value of normal dropout (between 0 and 1)\n",
        "        r_dropout -- (float, default : 0.0) value of recurrent dropout (between 0 and 1)\n",
        "        cell_activation -- (string, default : 'tanh') type of activation used in the cell (as required by Keras)\n",
        "    Returns :\n",
        "        model -- (Keras model object) resulting non-attention model\n",
        "    '''\n",
        "    # Chossing the cell type\n",
        "    get_cell = {\n",
        "        'RNN': keras.layers.SimpleRNN,\n",
        "        'GRU': keras.layers.GRU,\n",
        "        'LSTM': keras.layers.LSTM\n",
        "    }\n",
        "    # Encoder input and embedding\n",
        "    encoder_input = keras.layers.Input(shape=(None,), name=\"input_1\")\n",
        "    encoder_inp_emb = keras.layers.Embedding(encoder_vocab_size, inp_emb_size, name=\"embedding_1\")(encoder_input)\n",
        "\n",
        "    # Encoder cell layers\n",
        "    encoder_seq, *encoder_state = get_cell[cell_type](hid_layer_size, activation=cell_activation, return_sequences=True, return_state=True, \n",
        "                                                      dropout=dropout, recurrent_dropout=r_dropout, name=\"encoder_1\")(\n",
        "                                                            encoder_inp_emb\n",
        "                                                     )\n",
        "    for i in range(1, no_enc_layers):\n",
        "        encoder_seq, *encoder_state = get_cell[cell_type](hid_layer_size, activation=cell_activation, return_sequences=True, return_state=True, \n",
        "                                                          dropout=dropout, recurrent_dropout=r_dropout, name=\"encoder_\"+str(i+1))(\n",
        "                                                                encoder_seq\n",
        "                                                         )\n",
        "    \n",
        "    # Decoder input and embedding\n",
        "    decoder_input = keras.layers.Input(shape=(None,), name=\"input_2\")\n",
        "    decoder_inp_emb = keras.layers.Embedding(decoder_vocab_size, inp_emb_size, name=\"embedding_2\")(decoder_input)\n",
        "\n",
        "    # Decoder cell layers\n",
        "    decoder_seq, *_ = get_cell[cell_type](hid_layer_size, activation=cell_activation, return_sequences=True, return_state=True, \n",
        "                                          dropout=dropout, recurrent_dropout=r_dropout, name=\"decoder_1\")(\n",
        "                                                decoder_inp_emb, initial_state=encoder_state\n",
        "                                         )\n",
        "    for i in range(1, no_dec_layers):\n",
        "        decoder_seq, *_ = get_cell[cell_type](hid_layer_size, activation=cell_activation, return_sequences=True, return_state=True, \n",
        "                                              dropout=dropout, recurrent_dropout=r_dropout, name=\"decoder_\"+str(i+1))(\n",
        "                                                    decoder_seq, initial_state=encoder_state\n",
        "                                             )\n",
        "    \n",
        "    # Softmax FC layer\n",
        "    decoder_dense_output = keras.layers.Dense(decoder_vocab_size, activation=\"softmax\", name=\"dense_1\")(\n",
        "        decoder_seq\n",
        "    )\n",
        "\n",
        "    # Define the model that will turn encoder_input_data and decoder_input_data into decoder_target_data\n",
        "    model = keras.Model([encoder_input, decoder_input], decoder_dense_output)\n",
        "\n",
        "    model.summary(line_length=150)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-PJvBWTXsky",
        "outputId": "f40f2599-7370-448f-e55d-b89720925e69"
      },
      "source": [
        "# Installing and logging into WANDB\n",
        "!pip install --upgrade wandb\n",
        "!wandb login 6746f968d95eb71e281d6c7772a0469574430408\n",
        "\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/5f/45439b4767334b868e1c8c35b1b0ba3747d8c21be77b79f09eed7aa3c72b/wandb-0.10.30-py2.py3-none-any.whl (1.8MB)\n",
            "\r\u001b[K     |▏                               | 10kB 24.7MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 30.0MB/s eta 0:00:01\r\u001b[K     |▌                               | 30kB 19.3MB/s eta 0:00:01\r\u001b[K     |▊                               | 40kB 16.7MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 14.5MB/s eta 0:00:01\r\u001b[K     |█                               | 61kB 16.5MB/s eta 0:00:01\r\u001b[K     |█▎                              | 71kB 13.4MB/s eta 0:00:01\r\u001b[K     |█▌                              | 81kB 14.7MB/s eta 0:00:01\r\u001b[K     |█▋                              | 92kB 14.3MB/s eta 0:00:01\r\u001b[K     |█▉                              | 102kB 14.0MB/s eta 0:00:01\r\u001b[K     |██                              | 112kB 14.0MB/s eta 0:00:01\r\u001b[K     |██▏                             | 122kB 14.0MB/s eta 0:00:01\r\u001b[K     |██▍                             | 133kB 14.0MB/s eta 0:00:01\r\u001b[K     |██▌                             | 143kB 14.0MB/s eta 0:00:01\r\u001b[K     |██▊                             | 153kB 14.0MB/s eta 0:00:01\r\u001b[K     |███                             | 163kB 14.0MB/s eta 0:00:01\r\u001b[K     |███                             | 174kB 14.0MB/s eta 0:00:01\r\u001b[K     |███▎                            | 184kB 14.0MB/s eta 0:00:01\r\u001b[K     |███▍                            | 194kB 14.0MB/s eta 0:00:01\r\u001b[K     |███▋                            | 204kB 14.0MB/s eta 0:00:01\r\u001b[K     |███▉                            | 215kB 14.0MB/s eta 0:00:01\r\u001b[K     |████                            | 225kB 14.0MB/s eta 0:00:01\r\u001b[K     |████▏                           | 235kB 14.0MB/s eta 0:00:01\r\u001b[K     |████▍                           | 245kB 14.0MB/s eta 0:00:01\r\u001b[K     |████▌                           | 256kB 14.0MB/s eta 0:00:01\r\u001b[K     |████▊                           | 266kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 276kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 286kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 296kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 307kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 317kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 327kB 14.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 337kB 14.0MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 348kB 14.0MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 358kB 14.0MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 368kB 14.0MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 378kB 14.0MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 389kB 14.0MB/s eta 0:00:01\r\u001b[K     |███████                         | 399kB 14.0MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 409kB 14.0MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 419kB 14.0MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 430kB 14.0MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 440kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 450kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 460kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 471kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 481kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 491kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 501kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████                       | 512kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 522kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 532kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 542kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 552kB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 563kB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 573kB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 583kB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 593kB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 604kB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 614kB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 624kB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 634kB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 645kB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 655kB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 665kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 675kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 686kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 696kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 706kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 716kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 727kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 737kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 747kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 757kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 768kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 778kB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 788kB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 798kB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 808kB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 819kB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 829kB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 839kB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 849kB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 860kB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 870kB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 880kB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 890kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████                | 901kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 911kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 921kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 931kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 942kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 952kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 962kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 972kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 983kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 993kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.0MB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.0MB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.0MB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.0MB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.0MB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.1MB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.1MB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.1MB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.1MB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.1MB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.1MB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.1MB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.1MB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.1MB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.1MB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.2MB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.2MB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.2MB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.2MB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.2MB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.2MB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.2MB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.2MB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.2MB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.2MB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.3MB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.3MB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.3MB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.3MB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.3MB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.3MB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.3MB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.3MB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.3MB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.4MB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.4MB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.4MB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.4MB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.4MB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.4MB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.4MB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.4MB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.4MB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.4MB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.5MB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.5MB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.5MB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.5MB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.5MB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.5MB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.5MB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.5MB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.5MB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.5MB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.6MB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.6MB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.6MB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.6MB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.6MB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.6MB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.6MB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.6MB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.6MB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.6MB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.7MB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.7MB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.7MB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.7MB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.7MB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.7MB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.7MB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.7MB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.7MB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.8MB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.8MB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.8MB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.8MB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.8MB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.8MB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.8MB 14.0MB/s \n",
            "\u001b[?25hCollecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 14.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied, skipping upgrade: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/da/6f6224fdfc47dab57881fe20c0d1bc3122be290198ba0bf26a953a045d92/GitPython-3.1.17-py3-none-any.whl (166kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 53.4MB/s \n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/4a/a54b254f67d8f4052338d54ebe90126f200693440a93ef76d254d581e3ec/sentry_sdk-1.1.0-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 48.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (56.1.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 12.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: typing-extensions>=3.7.4.0; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: subprocess32, pathtools\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=4cc564d2a31044f81a7864f0eba49522b8493b1e81a72ddbf369f68ef4045e69\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=461aabd60f9979acda98b8b00ec60a3249245c7d921f6e808be0d779de334895\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "Successfully built subprocess32 pathtools\n",
            "Installing collected packages: configparser, subprocess32, shortuuid, docker-pycreds, smmap, gitdb, GitPython, pathtools, sentry-sdk, wandb\n",
            "Successfully installed GitPython-3.1.17 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.1.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.10.30\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxGrCkY2grXK"
      },
      "source": [
        "### Inference Model (without attention)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ozyl__IWdNvo"
      },
      "source": [
        "def create_inference_model(model):\n",
        "    '''\n",
        "    Function to return models needed for inference from the original model (without attention).\n",
        "    Arguments :\n",
        "        model -- (Keras model object) non-attention model used for training\n",
        "    Returns :\n",
        "        encoder_model -- (Keras model object) \n",
        "        deocder_model -- (Keras model object)\n",
        "        no_enc_layers -- (int) number of layers in the encoder\n",
        "        no_dec_layers -- (int) number of layers in the decoder\n",
        "    '''\n",
        "    # Calculating number of layers in encoder and decoder\n",
        "    no_enc_layers, no_dec_layers = 0, 0\n",
        "    for layer in model.layers:\n",
        "        no_enc_layers += layer.name.startswith('encoder')\n",
        "        no_dec_layers += layer.name.startswith('decoder')\n",
        "\n",
        "    # Encoder input\n",
        "    encoder_input = model.input[0]      # Input_1\n",
        "    # Encoder cell final layer\n",
        "    encoder_cell = model.get_layer(\"encoder_\"+str(no_enc_layers))\n",
        "    encoder_type = encoder_cell.__class__.__name__\n",
        "    encoder_seq, *encoder_state = encoder_cell.output\n",
        "    # Encoder model\n",
        "    encoder_model = keras.Model(encoder_input, encoder_state)\n",
        "\n",
        "    # Decoder input\n",
        "    decoder_input = model.input[1]      # Input_2\n",
        "    decoder_inp_emb = model.get_layer(\"embedding_2\")(decoder_input)\n",
        "    decoder_seq = decoder_inp_emb\n",
        "    # Inputs to decoder layers' initial states\n",
        "    decoder_states, decoder_state_inputs = [], []\n",
        "    for i in range(1, no_dec_layers+1):\n",
        "        if encoder_type == 'LSTM':\n",
        "            decoder_state_input = [keras.Input(shape=(encoder_state[0].shape[1],), name=\"input_\"+str(2*i+1)), \n",
        "                                   keras.Input(shape=(encoder_state[1].shape[1],), name=\"input_\"+str(2*i+2))]\n",
        "        else:\n",
        "            decoder_state_input = [keras.Input(shape=(encoder_state[0].shape[1],), name=\"input_\"+str(i+2))]\n",
        "\n",
        "        decoder_cell = model.get_layer(\"decoder_\"+str(i))\n",
        "        decoder_seq, *decoder_state = decoder_cell(decoder_seq, initial_state=decoder_state_input)\n",
        "        decoder_states += decoder_state\n",
        "        decoder_state_inputs += decoder_state_input\n",
        "\n",
        "    # Softmax FC layer\n",
        "    decoder_dense = model.get_layer(\"dense_1\")\n",
        "    decoder_dense_output = decoder_dense(decoder_seq)\n",
        "\n",
        "    # Decoder model\n",
        "    decoder_model = keras.Model(\n",
        "        [decoder_input] + decoder_state_inputs, [decoder_dense_output] + decoder_states\n",
        "    )\n",
        "\n",
        "    return encoder_model, decoder_model, no_enc_layers, no_dec_layers\n",
        "\n",
        "\n",
        "def convert_to_word(predictions, char_enc, char_dec = None):\n",
        "    # Function to return the predictions after cutting the END_CHAR and BLANK_CHAR s at the end.\n",
        "    # If char_dec == None, the predictions are in the form of decoded string, otherwise as list of integers\n",
        "    no_samples = len(predictions) if type(predictions) is list else predictions.shape[0]\n",
        "    pred_words = ['' for _ in range(no_samples)]\n",
        "    for i, pred_list in enumerate(predictions):\n",
        "        for l in pred_list:\n",
        "            # Stop word : END_CHAR\n",
        "            if l == char_enc[END_CHAR]:\n",
        "                break\n",
        "            pred_words[i] += char_dec[l] if char_dec is not None else l\n",
        "    \n",
        "    return pred_words\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nX3bMk8vgjCg"
      },
      "source": [
        "### Beam decoder (with/without attention) for inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfvzFIUKdYAw"
      },
      "source": [
        "def beam_decoder_infer(model, input_seqs, max_decoder_timesteps, K=1, target_seqs=None, starting_char_enc=0, batch_size=64, attention=False):\n",
        "    '''\n",
        "    Function to do inference on the model using beam decoder.\n",
        "    Arguments :\n",
        "        model -- (Keras model object) training model\n",
        "        input_seqs -- (numpy ndarray of size : (None, timesteps)) input to encoder\n",
        "        max_decoder_timesteps -- (int) Number of timesteps to infer in decoder\n",
        "        K -- (int, default : 1) beam width of beam decoder\n",
        "        target_seqs -- (numpy ndarray of size : (None, timesteps, decoder_vocab_size), deault : None) expected target.\n",
        "                       If None, cross entropy errors won't be calculated.\n",
        "        starting_char_enc -- (int, default : 0) Encoding integer for START_CHAR\n",
        "        batch_size -- (int, default : 64) batch_size sent to Keras predict\n",
        "        attention -- (bool, defualt : False) whether the model has attention or not\n",
        "    Returns :\n",
        "        final_outputs -- (numpy ndarray of size : (None, K, timesteps)) top K output sequences\n",
        "        final_errors -- (numpy ndarray of size : (None, K)) cross entropy errors for top K output (All zeros if target_seqs == None)\n",
        "        states_values -- (numpy ndarray of size : (K, None, timesteps, hid_layer_size))  hidden states of decoder\n",
        "        final_attn_scores -- (numpy ndarray of size : (None, K, decoder_timesteps, encoder_timesteps)) attention to all encoder timesteps for a decoder timestep \n",
        "    '''\n",
        "    # Generating output from encoder\n",
        "    encoder_model, decoder_model, no_enc_layers, no_dec_layers = create_attention_inference_model(model) if attention else create_inference_model(model)\n",
        "    encoder_output = encoder_model.predict(input_seqs, batch_size=batch_size)\n",
        "    encoder_out = encoder_output if type(encoder_output) is list else [encoder_output]\n",
        "\n",
        "    # Number of input samples in the data passed\n",
        "    no_samples = input_seqs.shape[0]\n",
        "\n",
        "    # Top K output sequences for each input \n",
        "    final_outputs = np.zeros((no_samples, K, max_decoder_timesteps), dtype=np.int32)\n",
        "    # Errors for top K output sequences for each input\n",
        "    final_errors = np.zeros((no_samples, K))\n",
        "    # Attention scores for top K output sequences for each input\n",
        "    final_attn_scores = np.zeros((no_samples, K, max_decoder_timesteps, input_seqs.shape[1]))\n",
        "\n",
        "    # decoder input sequence for 1 timestep (for all samples). Initially one choice only there\n",
        "    decoder_k_inputs = np.zeros((no_samples, 1, 1))\n",
        "    # Populate the input sequence with the start character at the 1st timestep\n",
        "    decoder_k_inputs[:, :, 0] = starting_char_enc\n",
        "\n",
        "    # (log(probability) sequence, decoder output sequence) pairs for all choices and all samples. Probability starts with log(1) = 0\n",
        "    decoder_k_out = [[(0, [])] for _ in range(no_samples)]\n",
        "    # Categorical cross entropy error in the sequence for all choice and all samples\n",
        "    errors = [[0] for _ in range(no_samples)]\n",
        "    # Output states from decoder for all choices, and all samples\n",
        "    states_values  = [encoder_out * no_dec_layers]\n",
        "\n",
        "    # Attention weights output\n",
        "    attn_k_scores = [[None] for _ in range(no_samples)]\n",
        "\n",
        "    # Sampling loop\n",
        "    for it in range(max_decoder_timesteps):\n",
        "        # Storing respective data for all possibilities\n",
        "        All_k_beams = [[] for _ in range(no_samples)]\n",
        "        All_decoder_states = [[] for _ in range(no_samples)]\n",
        "        All_errors = [[] for _ in range(no_samples)]\n",
        "        All_attn_scores = [[] for _ in range(no_samples)]\n",
        "\n",
        "        for k in range(len(decoder_k_out[0])):\n",
        "            if attention:\n",
        "                attn_score, decoder_output, *decoder_states = decoder_model.predict([input_seqs, decoder_k_inputs[:,k]] + states_values[k], batch_size=batch_size)\n",
        "            else:\n",
        "                decoder_output, *decoder_states = decoder_model.predict([decoder_k_inputs[:,k]] + states_values[k], batch_size=batch_size)\n",
        "\n",
        "            # Top K scores\n",
        "            top_k = np.argsort(decoder_output[:, -1, :], axis=-1)[:, -K:]\n",
        "            for b in range(no_samples):\n",
        "                All_k_beams[b] += [(\n",
        "                    decoder_k_out[b][k][0] + np.log(decoder_output[b, -1, top_k[b][i]]),\n",
        "                    decoder_k_out[b][k][1] + [top_k[b][i]]\n",
        "                ) for i in range(K)]\n",
        "\n",
        "                if attention:\n",
        "                    All_attn_scores[b] += [attn_score[b]] * K if attn_k_scores[b][k] is None \\\n",
        "                                          else [np.concatenate((attn_k_scores[b][k], attn_score[b]), axis=0)] * K\n",
        "            \n",
        "                if target_seqs is not None:\n",
        "                    All_errors[b] += [errors[b][k] - np.log(decoder_output[b, -1, target_seqs[b, it]])] * K\n",
        "                \n",
        "                All_decoder_states[b] += [[state[b:b+1] for state in decoder_states]] * K\n",
        "        \n",
        "        # Sort and choose top K with max probabilities\n",
        "        sorted_ind = list(range(len(All_k_beams[0])))\n",
        "        sorted_ind = [sorted(sorted_ind, key = lambda ix: All_k_beams[b][ix][0])[-K:][::-1] for b in range(no_samples)]\n",
        "        # Choose the top K decoder output sequences till now\n",
        "        decoder_k_out = [[All_k_beams[b][ind] for ind in sorted_ind[b]] for b in range(no_samples)]\n",
        "\n",
        "        # Update the input sequence for next 1 timestep\n",
        "        decoder_k_inputs = np.array([[All_k_beams[b][ind][1][-1] for ind in sorted_ind[b]] for b in range(no_samples)])\n",
        "\n",
        "        # Update states\n",
        "        states_values = [All_decoder_states[0][ind] for ind in sorted_ind[0]]\n",
        "        for b in range(1, no_samples):\n",
        "            states_values = [[np.concatenate((states_values[i][j], All_decoder_states[b][ind][j])) \n",
        "                              for j in range(len(All_decoder_states[b][ind]))] for i,ind in enumerate(sorted_ind[b])]\n",
        "\n",
        "        # Update attention scores\n",
        "        if attention:\n",
        "            attn_k_scores = [[All_attn_scores[b][ind] for ind in sorted_ind[b]] for b in range(no_samples)]\n",
        "\n",
        "        # Update errors\n",
        "        if target_seqs is not None:\n",
        "            errors = [[All_errors[b][ind] for ind in sorted_ind[b]] for b in range(no_samples)]\n",
        "\n",
        "    final_outputs = np.array([[decoder_k_out[b][i][1] for i in range(K)] for b in range(no_samples)])\n",
        "    if target_seqs is not None:\n",
        "        final_errors = np.array(errors) / max_decoder_timesteps\n",
        "    if attention:\n",
        "        final_attn_scores = np.array(attn_k_scores)\n",
        "\n",
        "    return final_outputs, final_errors, np.array(states_values), final_attn_scores\n",
        "\n",
        "\n",
        "def calc_metrics(k_outputs, target_seqs, char_enc, char_dec, k_errors=None, exact_word=True):\n",
        "    # Calculates the accuracy (and mean error if info provided) for the best of K possible output sequences\n",
        "    # target_seqs -- Expected output (encoded sequence)\n",
        "    # k_outputs -- k choices of output sequences for each sample\n",
        "\n",
        "    matches = np.mean(k_outputs == np.repeat(target_seqs.reshape((target_seqs.shape[0], 1, target_seqs.shape[1])), k_outputs.shape[1], axis=1), axis=-1)\n",
        "    best_k = np.argmax(matches, axis=-1)\n",
        "    best_ind = (tuple(range(best_k.shape[0])), tuple(best_k))\n",
        "    accuracy = np.mean(matches[best_ind])\n",
        "\n",
        "    loss = None\n",
        "    if k_errors is not None:\n",
        "        loss = np.mean(k_errors[best_ind])\n",
        "    if exact_word:\n",
        "        equal = [0] * k_outputs.shape[0]\n",
        "        true_out = convert_to_word(target_seqs, char_enc, char_dec)\n",
        "        for k in range(k_outputs.shape[1]):\n",
        "            pred_out = convert_to_word(k_outputs[:,k], char_enc, char_dec)\n",
        "            equal = [equal[i] or (pred_out[i] == true_out[i]) for i in range(k_outputs.shape[0])]\n",
        "        exact_accuracy = np.mean(equal)\n",
        "\n",
        "        return accuracy, exact_accuracy, loss\n",
        "    \n",
        "    return accuracy, loss\n",
        "\n",
        "\n",
        "def beam_decoder(model, input_seqs, target_seqs_onehot, max_decoder_timesteps, char_enc, char_dec, K=1, \n",
        "                 model_batch_size=64, attention=False, infer_batch_size=512, exact_word=True, return_outputs=False, \n",
        "                 return_states=False, return_attn_scores=False):\n",
        "    '''\n",
        "    Function to calculate/capture character-wise accuracy, exact-word-match accuracy, and loss for the seq2seq model using a beam decoder.\n",
        "    Arguments :\n",
        "        model -- (Keras model object) model used for training\n",
        "        input_seqs -- (numpy ndarray of size : (None, timesteps)) input to encoder (where characters are encoded as integers)\n",
        "        target_seqs -- (numpy ndarray of size : (None, timesteps, decoder_vocab_size)) expected target in onehot format\n",
        "        max_decoder_timesteps -- (int) Number of timesteps to infer in decoder\n",
        "        char_enc -- (dict) target character encoding\n",
        "        char_dec -- (list) target character decoding\n",
        "        K -- (int, default : 1) beam width to be used in beam decoder\n",
        "        model_batch_size -- (int, default : 64) batch size to be used while evaluating model using Keras\n",
        "        attention -- (bool, defualt : False) whether the model has attention or not\n",
        "        infer_batch_size -- (int, default : 512) number of samples to be sent to beam_decoder_infer() at a time (to avoid RAM memory overshoot problems).\n",
        "                            We have set the default model_batch_size and infer_batch_size such that it takes the least time to run and runs without problems in Google Colab.\n",
        "        exact_word -- (bool, default : True) whether or not exact_accuracy has (If True, will be returned as the next argument after accuracy)\n",
        "        return_outputs -- (bool, default : True) whether or not the outputs predicted need to be returned\n",
        "        return_states -- (bool, default : True) whether or not the decoder hidden states need to be returned (for further training, another sequential model addition, etc)\n",
        "        return_attn_scores -- (bool, default : True) whether or not the attention scores need to be returned\n",
        "    Returns :\n",
        "        accuracy -- (float) the character-wise match accuracy (as calculated by Keras fit)\n",
        "        (If exact_word is True) exact_accuracy -- (float) the exact word match accuracy\n",
        "        loss -- (float) the cross-entropy loss for the top K predictions\n",
        "        (If return_outputs is True) k_outputs -- (numpy ndarray of size : (None, K, timesteps)) top K output sequences\n",
        "        (If return_states is True) k_states -- (numpy ndarray of size : (K, None, timesteps, hid_layer_size))  hidden states of decoder\n",
        "        (If return_attn_scores is True) k_attn_scores -- (numpy ndarray of size : (None, K, decoder_timesteps, encoder_timesteps)) attention scores\n",
        "    '''\n",
        "    target_seqs = np.argmax(target_seqs_onehot, axis=-1)\n",
        "    k_outputs, k_errors, k_states, k_attn_scores = None, None, None, None\n",
        "    for i in range(0, input_seqs.shape[0], infer_batch_size):\n",
        "        tmp_k_outputs, tmp_k_errors, tmp_k_states, tmp_k_attn_scores = beam_decoder_infer(model, input_seqs[i:i+infer_batch_size], \n",
        "                                                                                          max_decoder_timesteps, K, \n",
        "                                                                                          target_seqs[i:i+infer_batch_size], char_enc['\\t'], \n",
        "                                                                                          model_batch_size, attention)\n",
        "        if k_errors is None:\n",
        "            k_outputs, k_errors, k_states, k_attn_scores = tmp_k_outputs, tmp_k_errors, tmp_k_states, tmp_k_attn_scores\n",
        "        else:\n",
        "            k_outputs = np.concatenate((k_outputs, tmp_k_outputs))\n",
        "            k_errors = np.concatenate((k_errors, tmp_k_errors))\n",
        "            k_states = np.concatenate((k_states, tmp_k_states), axis=2)\n",
        "            k_attn_scores = np.concatenate((k_attn_scores, tmp_k_attn_scores))\n",
        "\n",
        "    return_elements = []\n",
        "    if return_outputs:\n",
        "        return_elements += [k_outputs]\n",
        "    if return_states:\n",
        "        return_elements += [k_states]\n",
        "    if return_attn_scores:\n",
        "        return_elements += [k_attn_scores]\n",
        "\n",
        "    if len(return_elements) > 0:\n",
        "        return calc_metrics(k_outputs, target_seqs, char_enc, char_dec, k_errors, exact_word) + tuple(return_elements)\n",
        "\n",
        "    return calc_metrics(k_outputs, target_seqs, char_enc, char_dec, k_errors, exact_word)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzglbAEWgdkX"
      },
      "source": [
        "### Training (without attention)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbxGPFfs_Vtv"
      },
      "source": [
        "class customValidation(keras.callbacks.Callback):\n",
        "    # Custom class to provide callback after each epoch of training to calculate custom metrics for validation set with beam decoder\n",
        "    def __init__(self, val_enc_input, val_dec_target, beam_width=1, batch_size=64, attention=False):\n",
        "        self.beam_width = beam_width\n",
        "        self.validation_input = val_enc_input\n",
        "        self.validation_target = val_dec_target\n",
        "        self.batch_size = batch_size\n",
        "        self.attention = attention\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs):\n",
        "        val_accuracy, val_exact_accuracy, val_loss = beam_decoder(self.model, self.validation_input, self.validation_target, max_decoder_seq_length, \n",
        "                                                                  target_char_enc, target_char_dec, self.beam_width, self.batch_size, self.attention)\n",
        "\n",
        "        # Log them to reflect in WANDB callback and EarlyStopping\n",
        "        logs[\"val_accuracy\"] = val_accuracy\n",
        "        logs[\"val_exact_accuracy\"] = val_exact_accuracy\n",
        "        logs[\"val_loss\"] = val_loss             # Validation loss calculates categorical cross entropy loss\n",
        "\n",
        "        print(\"— val_loss: {:.4f} — val_accuracy: {:.4f} — val_exact_accuracy: {:.4f}\".format(val_loss, val_accuracy, val_exact_accuracy))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClA5ym6tw2fp"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Nadam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "def train_model(model, train_input_data, train_target_data, val_input_data, val_target_data, beam_width = 1, attention = False,\n",
        "                batch_size = 64, optimizer = 'adam', learning_rate = 1e-3, epochs = 10, loss_fn = 'categorical_crossentropy'):\n",
        "    # Function to train the model using the mentioned optimizer, learning rate and epochs using given training and validation data\n",
        "\n",
        "    if optimizer == 'adam':\n",
        "        model.compile(optimizer = Adam(learning_rate=learning_rate), loss = loss_fn, metrics = ['accuracy'])\n",
        "    elif optimizer == 'momentum':\n",
        "        model.compile(optimizer = SGD(learning_rate=learning_rate, momentum = 0.9), loss = loss_fn, metrics = ['accuracy'])\n",
        "    elif optimizer == 'rmsprop':\n",
        "        model.compile(optimizer = RMSprop(learning_rate=learning_rate), loss = loss_fn, metrics = ['accuracy'])\n",
        "    elif optimizer == 'nesterov':\n",
        "        model.compile(optimizer = SGD(learning_rate=learning_rate, momentum = 0.9, nesterov = True), loss = loss_fn, metrics = ['accuracy'])\n",
        "    elif optimizer == 'nadam':\n",
        "        model.compile(optimizer = Nadam(learning_rate=learning_rate), loss = loss_fn, metrics = ['accuracy'])\n",
        "    else:\n",
        "        model.compile(optimizer = SGD(learning_rate=learning_rate), loss = loss_fn, metrics = ['accuracy'])\n",
        "\n",
        "    # Using validation accuracy as the metric to monitor as that is what is intended to be maximized\n",
        "    model.fit(train_input_data,\n",
        "              train_target_data,\n",
        "              batch_size = batch_size,\n",
        "              epochs = epochs, \n",
        "              verbose = 2,\n",
        "              callbacks = [customValidation(val_input_data[0], val_target_data, beam_width, batch_size, attention), \n",
        "                           WandbCallback(monitor='val_accuracy'), EarlyStopping(monitor='val_accuracy', patience=5)])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAUGuzLFZoRg"
      },
      "source": [
        "# Sample config dictionary (contains the best model config) that will be sent to WANDB run as default configurations (for no attention models)\n",
        "config_1 = {\n",
        "    \"learning_rate\": 1e-3,                                      # Learning rate in gradient descent\n",
        "    \"epochs\": 10,                                               # Number of epochs to train the model   \n",
        "    \"optimizer\": 'adam',                                        # Gradient descent algorithm used for the parameter updation\n",
        "    \"batch_size\": 64,                                           # Batch size used for the optimizer\n",
        "    \"loss_function\": 'categorical_crossentropy',                # Loss function used in the optimizer\n",
        "    \"architecture\": 'RNN',                                      # Type of neural network used\n",
        "    \"dataset\": \"Dakshina\",                                      # Name of dataset\n",
        "    \"inp_emb_size\": 256,                                         \n",
        "    \"no_enc_layers\": 3,                                         \n",
        "    \"no_dec_layers\": 3,                                         \n",
        "    \"hid_layer_size\": 256,                                       \n",
        "    \"dropout\" : 0.25,                                           \n",
        "    \"cell_type\": 'GRU',\n",
        "    \"beam_width\": 5,\n",
        "    \"attention\": False\n",
        "}\n",
        "\n",
        "import yaml\n",
        "\n",
        "def seq2seq_no_attention(config, load_model=None, wandb_init=True):\n",
        "  '''\n",
        "  Function to load/create a model (without attention) and train it.\n",
        "  Arguments :\n",
        "    config -- (dict) configurations of parameters and hyperparameters ot be used for creating the model. if load_model is not None, this isn't necessary.\n",
        "                (the dictionary should contain the keys that are mentioned in config_1)\n",
        "    load_model -- (string, default : None) WANDB run ID of the model to train further. The configurations will be read from WANDB as well.\n",
        "    wandb_init -- (bool, default : True) whther or not WANDB run needs to be initiated (if this function is used as part of sweep alone, this would be False)\n",
        "  Returns :\n",
        "    model -- (Keras model object) trained model\n",
        "    config -- (dict) configuration dictionary\n",
        "    id -- (string) WANDB run ID used for training the model\n",
        "  '''\n",
        "  if load_model is not None:\n",
        "    api = wandb.Api()\n",
        "    prev_run = api.run('abisheks/assignment3/'+load_model)\n",
        "    prev_model_file = prev_run.file('model-best.h5').download(replace=True)\n",
        "    model = keras.models.load_model(prev_model_file.name)\n",
        "    config_file = prev_run.file('config.yaml').download(replace=True)\n",
        "    with open(config_file.name, 'r') as file:\n",
        "      config_tmp = yaml.safe_load(file)\n",
        "    config = {}\n",
        "    config['attention'] = False\n",
        "    for key in ['learning_rate', 'epochs', 'optimizer', 'batch_size', 'loss_function', 'architecture', 'dataset', 'inp_emb_size', 'no_enc_layers', \\\n",
        "                'no_dec_layers', 'hid_layer_size', 'dropout', 'cell_type', 'beam_width']:\n",
        "      config[key] = config_tmp[key]['value']\n",
        "  else:\n",
        "    model = create_model(len(input_char_dec), len(target_char_dec), config['inp_emb_size'], config['no_enc_layers'], \n",
        "                         config['no_dec_layers'], config['hid_layer_size'], config['cell_type'], config['dropout'], config['dropout'])\n",
        "  \n",
        "  id = None\n",
        "  if wandb_init:\n",
        "    id = wandb.util.generate_id()\n",
        "    run = wandb.init(id = id, project=\"assignment3\", entity=\"abisheks\", reinit=True, config=config)\n",
        "    wandb.run.name = f\"ie_{config['inp_emb_size']}_ne_{config['no_enc_layers']}_de_{config['no_dec_layers']}_ct_{config['cell_type']}_dr_{config['dropout']}\"\n",
        "    wandb.run.name += f\"_da_{config['hid_layer_size']}_K_{config['beam_width']}_attn_{False}\"\n",
        "    wandb.run.save()\n",
        "    print(wandb.run.name)\n",
        "  \n",
        "  model = train_model(model, [train_enc_input,train_dec_input], train_dec_target, [val_enc_input,val_dec_input], val_dec_target, config['beam_width'],\n",
        "                      config['attention'], config['batch_size'], config['optimizer'], config['learning_rate'], config['epochs'], config['loss_function'])\n",
        "  \n",
        "  if wandb_init:\n",
        "    run.finish()\n",
        "\n",
        "  return model, config, id\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqUOQ86Nf8Kr"
      },
      "source": [
        "### Sweep (models without attention)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVUmL1bU4Rkf"
      },
      "source": [
        "# Hyperparameter choices to sweep \n",
        "sweep_config_1 = {\n",
        "    'name': 'RNN',\n",
        "    'method': 'bayes',                   # Possible search : grid, random, bayes\n",
        "    'metric': {\n",
        "      'name': 'val_accuracy',\n",
        "      'goal': 'maximize'   \n",
        "    },\n",
        "    'parameters': {\n",
        "        'inp_emb_size': {\n",
        "            'values': [32, 64, 256]\n",
        "        },\n",
        "        'no_enc_layers': {\n",
        "            'values': [1, 2, 3]\n",
        "        },\n",
        "        'no_dec_layers': {\n",
        "            'values': [1, 2, 3]\n",
        "        },\n",
        "        'hid_layer_size': {\n",
        "            'values': [32, 64, 256]\n",
        "        },\n",
        "        'cell_type': {\n",
        "            'values': ['RNN', 'LSTM', 'GRU']\n",
        "        },\n",
        "        'dropout' :{\n",
        "            'values': [0, 0.25, 0.4]\n",
        "        },\n",
        "        'beam_width': {\n",
        "            'values': [1, 5]\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa8cfQE6uZI3"
      },
      "source": [
        "def sweep_wrapper():\n",
        "    # Wrapper function to call the seq2seq_no_attention() function for sweeping with different hyperparameters\n",
        "\n",
        "    # Initialize a new wandb run\n",
        "    run = wandb.init(config=config_1, reinit=True)\n",
        "\n",
        "    # Config is a variable that holds and saves hyperparameters and inputs\n",
        "    config = wandb.config\n",
        "\n",
        "    wandb.run.name = f'ie_{config.inp_emb_size}_ne_{config.no_enc_layers}_de_{config.no_dec_layers}_ct_{config.cell_type}_dr_{config.dropout}'\n",
        "    wandb.run.name += f'_da_{config.hid_layer_size}_K_{config.beam_width}'\n",
        "    wandb.run.save()\n",
        "    print(wandb.run.name)\n",
        "\n",
        "    model, *_ = seq2seq_no_attention(config, wandb_init=False)\n",
        "    run.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qswMgpZe9mqx"
      },
      "source": [
        "# Question 2 - sweep for no attention models\n",
        "######################### UNCOMMENT BELOW CODE TO RUN ##########################\n",
        "\n",
        "# sweep_id = wandb.sweep(sweep_config_1, entity=\"abisheks\", project=\"assignment3\")\n",
        "# wandb.agent(sweep_id, lambda : sweep_wrapper())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5I_vU7-Rf4Ar"
      },
      "source": [
        "### Test accuracy and sample input/output for best model (without attention)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMF9NzNiESCT"
      },
      "source": [
        "def levenshtein(s1, s2):\n",
        "    # Function to calculate levenshtein distance between two sequences usign Dynamic Programming\n",
        "    m, n = len(s1)+1, len(s2)+1\n",
        "    # Initialisation\n",
        "    dp = np.zeros((m, n))\n",
        "    # Base case\n",
        "    dp[0,1:] = np.arange(1,n)\n",
        "    dp[1:,0] = np.arange(1,m)\n",
        "\n",
        "    # Recursion\n",
        "    for i in range(1,m):\n",
        "        for j in range(1,n):\n",
        "            if s1[i-1] == s2[j-1]:\n",
        "                dp[i,j] = min(dp[i-1,j-1], dp[i-1,j]+1, dp[i,j-1]+1)\n",
        "            else:\n",
        "                dp[i,j] = min(dp[i,j-1], dp[i-1,j], dp[i-1,j-1]) + 1\n",
        "    \n",
        "    return dp[m-1,n-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2ctN_YL8SNv"
      },
      "source": [
        "# To plot the model graph\n",
        "from keras.utils.vis_utils import plot_model\n",
        "# To save the predictions to a csv file\n",
        "import csv\n",
        "\n",
        "def test_model(run_id, test_enc_input, test_dec_target, max_decoder_seq_length, target_char_enc, target_char_dec, attention=False, save_pred=False, test_input=None):\n",
        "    '''\n",
        "    Function to evaluate the model metrics on test data and optionally save the predictions.\n",
        "    Arguments :\n",
        "        run_id -- (string) WANDB run ID for the trained model\n",
        "        test_enc_input -- (numpy ndarray of size : (None, timesteps)) input to encoder (where characters are encoded as integers)\n",
        "        test_dec_target -- (numpy ndarray of size : (None, timesteps, decoder_vocab_size)) expected target in onehot format\n",
        "        max_decoder_seq_length -- (int) number of timesteps in the decoder\n",
        "        target_enc_enc -- (dict) target character encoding\n",
        "        target_char_dec -- (list) target character decoding\n",
        "        attention -- (bool, default : False) whether or not the model uses attention\n",
        "        save_pred -- (bool, default : False) whether or not to save the predictions in a csv file\n",
        "        test_input -- (list of string : (no_samples, input word), default : None) input as words (needed while saving predictions to file alone)\n",
        "    Returns :\n",
        "        acc -- (float) character-wise match accuracy\n",
        "        exact_K_acc -- (float) exact word match accuracy using the beam width for the model\n",
        "        exact_acc -- (float) exact word match accuracy using the first prediction (which is equivalent to beam width = 1)\n",
        "        loss -- (float) loss value\n",
        "        true_out -- (list of string : (no_samples, word)) true output  \n",
        "        pred_out -- (2D list of string : (no_samples, K, word)) predicted output\n",
        "        pred_scores -- (2D list : (no_samples, K)) levenshtein distance of prediction to true output\n",
        "        (If attention is True) attn_scores -- (numpy ndarray of size : (None, K, decoder_timesteps, encoder_timesteps)) attention scores\n",
        "        model -- (Keras model object) the model obtained from the run\n",
        "    '''\n",
        "    api = wandb.Api()\n",
        "    prev_run = api.run('abisheks/assignment3/'+run_id)\n",
        "    prev_model_file = prev_run.file('model-best.h5').download(replace=True)\n",
        "    if attention:\n",
        "        model = keras.models.load_model(prev_model_file.name, custom_objects={'AttentionLayer': AttentionLayer})\n",
        "    else:\n",
        "        model = keras.models.load_model(prev_model_file.name)\n",
        "    config_file = prev_run.file('config.yaml').download(replace=True)\n",
        "    with open(config_file.name, 'r') as file:\n",
        "        config = yaml.safe_load(file)\n",
        "        \n",
        "\n",
        "    no_samples, K, batch_size = test_enc_input.shape[0], config['beam_width']['value'], config['batch_size']['value']\n",
        "    acc, exact_K_acc, loss, outputs, attn_scores = beam_decoder(model, test_enc_input, test_dec_target, max_decoder_seq_length, target_char_enc, \n",
        "                                                                target_char_dec, K, batch_size, attention,\n",
        "                                                                return_outputs=True, return_attn_scores=True)\n",
        "    \n",
        "    print(f'Test accuracy (using exact word match with beam width = {K}) : {exact_K_acc*100:.2f}%')\n",
        "\n",
        "    test_target = np.argmax(test_dec_target, axis=-1)\n",
        "    true_out = convert_to_word(test_target, target_char_enc, target_char_dec)\n",
        "    pred_out = [[] for _ in range(no_samples)]\n",
        "    pred_scores = [[] for _ in range(no_samples)]\n",
        "    for k in range(K):\n",
        "        pred = convert_to_word(outputs[:,k], target_char_enc, target_char_dec)\n",
        "        pred_out = [pred_out[b] + [pred[b]] for b in range(no_samples)]\n",
        "        pred_scores = [pred_scores[b] + [levenshtein(pred[b], true_out[b])] for b in range(no_samples)]\n",
        "    \n",
        "    equal = [pred_out[i][0] == true_out[i] for i in range(no_samples)]\n",
        "    exact_acc = np.mean(equal)\n",
        "\n",
        "    print(f'Test accuracy (using exact word match of the first prediction) : {exact_acc*100:.2f}%')\n",
        "    print('\\n')\n",
        "    \n",
        "    # We write the input and top K outputs in decreasing order of probabilities to the file\n",
        "    pred_file_name = 'predictions_vanilla.csv' if not attention else 'predictions_attention.csv'\n",
        "    with open(pred_file_name, 'w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\"Input\"] + [\"Prediction_\"+str(k) for k in range(K)])\n",
        "        for b in range(no_samples):\n",
        "            writer.writerow([test_input[b]] + [pred_out[b][k] for k in range(K)])\n",
        "\n",
        "    if attention:\n",
        "        return acc, exact_K_acc, exact_acc, loss, true_out, pred_out, pred_scores, attn_scores, model\n",
        "    return acc, exact_K_acc, exact_acc, loss, true_out, pred_out, pred_scores, model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "149Lm8kellS0"
      },
      "source": [
        "import matplotlib\n",
        "\n",
        "def get_clr(value, cmap=None):\n",
        "  # Function to get appropriate color for a value between 0 and 1 from the default blue to red hard-coded colors or a matplotlib cmap \n",
        "  colors = ['#85c2e1', '#89c4e2', '#95cae5', '#99cce6', '#a1d0e8',\n",
        "    '#b2d9ec', '#baddee', '#c2e1f0', '#eff7fb', '#f9e8e8',\n",
        "    '#f9e8e8', '#f9d4d4', '#f9bdbd', '#f8a8a8', '#f68f8f',\n",
        "    '#f47676', '#f45f5f', '#f34343', '#f33b3b', '#f42e2e']\n",
        "  if cmap is not None:\n",
        "      rgba = matplotlib.cm.get_cmap(cmap)(value)\n",
        "      return 'rgb'+str(tuple([int(c*255) for c in rgba[:-1]]))\n",
        "  value = min(int((value * 100) / 5), 19)\n",
        "  return colors[value]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROfEI42K5mHe"
      },
      "source": [
        "from IPython.display import HTML as html_print\n",
        "from IPython.display import display\n",
        "\n",
        "def print_samples(input, true_out, pred_out, pred_scores, rand_seq=None):\n",
        "    '''\n",
        "    Function to print sample outputs in a neat format\n",
        "    Arguments :\n",
        "        input -- input words\n",
        "        true_out -- true output as words\n",
        "        pred_out -- K predicted output words\n",
        "        pred_scores -- levenshtein distance for the predictions to the true output\n",
        "        rand_seq -- list of indices from the dataset passed for which the sample outputs are to be printed (If None, random 10 samples will be chosen)\n",
        "    Returns :\n",
        "        rand_seq -- the list of indices for which sample outputs are printed\n",
        "    '''\n",
        "    no_samples = len(true_out)\n",
        "    if rand_seq is None:\n",
        "        rand_seq = np.random.randint(no_samples, size=(10,))\n",
        "    print('-'*20 + f' Top {len(pred_scores[0])} predictions in decreasing order of probabilities for 10 random samples ' + '-'*20)\n",
        "    print('')\n",
        "    for i in rand_seq:\n",
        "        K = len(pred_scores[i])\n",
        "        html_str = '''\n",
        "        <table style=\"border:2px solid black; border-collapse:collapse\">\n",
        "        <caption> <strong>INPUT :</strong> {} &emsp; | &emsp; <strong> TRUE OUTPUT : </strong> {} </caption>\n",
        "        <tr>\n",
        "        <th scope=\"row\" style=\"border:1px solid black;padding:10px;text-align:left\"> Top {} Predictions </th>\n",
        "        '''.format(input[i], true_out[i], K)\n",
        "        for k in range(K):\n",
        "            html_str += '''\n",
        "            <td style=\"color:#000;background-color:{};border:1px solid black;padding:10px\"> {} </td>\n",
        "            '''.format(get_clr(pred_scores[i][k]/5), pred_out[i][k])\n",
        "        html_str += '''\n",
        "        </tr>\n",
        "        <tr>\n",
        "        <th scope=\"row\" style=\"border:1px solid black;padding:10px;text-align:left\"> Levenshtein distance (to true output) &emsp; </th>\n",
        "        '''\n",
        "        for k in range(K):\n",
        "            html_str += '''\n",
        "            <td style=\"border:1px solid black;padding:10px\"> {} </td>\n",
        "            '''.format(pred_scores[i][k])\n",
        "        html_str += '''\n",
        "        </tr>\n",
        "        </table>\n",
        "        '''\n",
        "        display(html_print(html_str))\n",
        "        print('\\n\\n')\n",
        "    \n",
        "    return rand_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "7EBhDu1s8Zw1",
        "outputId": "abd89bda-cfa5-4a6a-d8ba-064c880a195a"
      },
      "source": [
        "# Question 4b - sample inputs for no attention models\n",
        "######################### UNCOMMENT BELOW CODE TO RUN ##########################\n",
        "\n",
        "test1_acc, test1_exact_K_acc, test1_exact_acc, test1_loss, test1_true_out, \\\n",
        "test1_pred_out, test1_pred_scores, model1 = test_model('ddhrh5hn', test_enc_input, \n",
        "                                                       test_dec_target, \n",
        "                                                       max_decoder_seq_length, \n",
        "                                                       target_char_enc, \n",
        "                                                       target_char_dec, \n",
        "                                                       False)\n",
        "\n",
        "# random_samples contain the list of sample indices from test data for which outputs were printed\n",
        "random_samples = print_samples(test_inp, test1_true_out, test1_pred_out, test1_pred_scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer encoder_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer encoder_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer encoder_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer decoder_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer decoder_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer decoder_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Test accuracy (using exact word match with beam width = 5) : 71.02%\n",
            "Test accuracy (using exact word match of the first prediction) : 39.61%\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-2f521f4b70ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                                                        \u001b[0mtarget_char_enc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                                        \u001b[0mtarget_char_dec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                                                        False)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# random_samples contain the list of sample indices from test data for which outputs were printed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-64f7555aa70a>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(run_id, test_enc_input, test_dec_target, max_decoder_seq_length, target_char_enc, target_char_dec, attention, save_pred, test_input)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Input\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Prediction_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpred_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TLmpWZME_e6"
      },
      "source": [
        "The 10 random samples used for the outputs in report : \n",
        "\n",
        "[3026, 3263, 2995, 1568, 1946, 3602, 2528, 1203, 3612, 702]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVBHyEpYATKR"
      },
      "source": [
        "### Best model (without attention) summary plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_l6sNsq-pWd"
      },
      "source": [
        "# To visualise the best model (without attention) ------ NOTE!! Uncomment the above cell also before running this cell\n",
        "######################### UNCOMMENT BELOW CODE TO RUN ##########################\n",
        "\n",
        "plot_model(model1, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3SXOwppmVux"
      },
      "source": [
        "# Seq2Seq Model (with Attention)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPnn4m3Fg6WY"
      },
      "source": [
        "### Creating Custom Attention layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE3M6O-LXlII"
      },
      "source": [
        "from keras.layers import Layer\n",
        "import keras.backend as K\n",
        "\n",
        "class AttentionLayer(Layer):\n",
        "    \"\"\"\n",
        "    This Attention layer class code is used from : https://github.com/thushv89/attention_keras/blob/master/src/layers/attention.py\n",
        "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
        "    There are three sets of weights introduced W_a, U_a, and V_a\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        # Create a trainable weight variable for this layer.\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs, verbose=False):\n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "        if verbose:\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            \"\"\" Step function for computing energy for a single decoder state\n",
        "            inputs: (batchsize * 1 * de_in_dim)\n",
        "            states: (batchsize * 1 * de_latent_dim)\n",
        "            \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch size * en_seq_len * latent_dim\n",
        "            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "            if verbose:\n",
        "                print('Ua.h>', U_a_dot_h.shape)\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', Ws_plus_Uh.shape)\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
        "        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            # (batch_size, decoder_timesteps, decoder_hid_layer_size)\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            # (batch_size, decoder_timesteps, encoder_timesteps)\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsYMPjkIhB3B"
      },
      "source": [
        "### Creating model (with attention)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB6bPH59m0cA"
      },
      "source": [
        "def create_attention_model(encoder_vocab_size, decoder_vocab_size, inp_emb_size=64, no_enc_layers=1, no_dec_layers=1, \n",
        "                           hid_layer_size=64, cell_type='LSTM', dropout=0, r_dropout=0, cell_activation='tanh'):\n",
        "    '''\n",
        "    Function to create a seq2seq model with attention.\n",
        "    Arguments :\n",
        "        encoder_vocab_size -- (int) number of characters in input vocabulary\n",
        "        decoder_vocab_size -- (int) number of characters in output vocabulary\n",
        "        inp_emb_size -- (int, default : 64) size of input embedding layer for encoder and decoder\n",
        "        no_enc_layers -- (int, default : 1) number of layers of cell to stack in encoder\n",
        "        no_dec_layers -- (int, default : 1) number of layers of cell to stack in decoder\n",
        "        hid_layer_size -- (int, default : 64) size of hidden layer of the encoder and decoder cells\n",
        "        cell_type -- (string, default : 'LSTM') type of cell used in encoder and decoder (possible values : 'LSTM', 'GRU', 'RNN')\n",
        "        dropout -- (float, default : 0.0) value of normal dropout (between 0 and 1)\n",
        "        r_dropout -- (float, default : 0.0) value of recurrent dropout (between 0 and 1)\n",
        "        cell_activation -- (string, default : 'tanh') type of activation used in the cell (as required by Keras)\n",
        "    Returns :\n",
        "        model -- (Keras model object) resulting attention model\n",
        "    '''\n",
        "    # Getting cell type\n",
        "    get_cell = {\n",
        "        'RNN': keras.layers.SimpleRNN,\n",
        "        'GRU': keras.layers.GRU,\n",
        "        'LSTM': keras.layers.LSTM\n",
        "    }\n",
        "    # Encoder input and embedding\n",
        "    encoder_input = keras.layers.Input(shape=(None,), name=\"input_1\")\n",
        "    encoder_inp_emb = keras.layers.Embedding(encoder_vocab_size, inp_emb_size, name=\"embedding_1\")(encoder_input)\n",
        "\n",
        "    # Encoder cell layers\n",
        "    encoder_seq, *encoder_state = get_cell[cell_type](hid_layer_size, activation=cell_activation, return_sequences=True, return_state=True, \n",
        "                                                      dropout=dropout, recurrent_dropout=r_dropout, name=\"encoder_1\")(\n",
        "                                                            encoder_inp_emb\n",
        "                                                     )\n",
        "    for i in range(1, no_enc_layers):\n",
        "        encoder_seq, *encoder_state = get_cell[cell_type](hid_layer_size, activation=cell_activation, return_sequences=True, return_state=True, \n",
        "                                                          dropout=dropout, recurrent_dropout=r_dropout, name=\"encoder_\"+str(i+1))(\n",
        "                                                                encoder_seq\n",
        "                                                         )\n",
        "    # Decoder input and embedding\n",
        "    decoder_input = keras.layers.Input(shape=(None,), name=\"input_2\")\n",
        "    decoder_inp_emb = keras.layers.Embedding(decoder_vocab_size, inp_emb_size, name=\"embedding_2\")(decoder_input)\n",
        "    decoder_seq = decoder_inp_emb\n",
        "    # Decoder cell layers\n",
        "    for i in range(no_dec_layers-1):\n",
        "        decoder_seq, *_ = get_cell[cell_type](hid_layer_size, activation=cell_activation, return_sequences=True, return_state=True, \n",
        "                                              dropout=dropout, recurrent_dropout=r_dropout, name=\"decoder_\"+str(i+1))(\n",
        "                                                    decoder_seq, initial_state=encoder_state\n",
        "                                             )\n",
        "    # Decoder last layer\n",
        "    decoder_seq, *_ = get_cell[cell_type](hid_layer_size, activation=cell_activation, return_sequences=True, return_state=True, \n",
        "                                          dropout=dropout, recurrent_dropout=r_dropout, name=\"decoder_1\")(\n",
        "                                                decoder_inp_emb, initial_state=encoder_state\n",
        "                                         )\n",
        "\n",
        "    # Attention layer\n",
        "    attn_out, attn_scores = AttentionLayer(name='attention_1')([encoder_seq, decoder_seq])        # Bahdanau Attention\n",
        "    # Concat attention output and decoder output\n",
        "    dense_concat_input = keras.layers.Concatenate(axis=-1, name='concat_layer_1')([decoder_seq, attn_out])\n",
        "\n",
        "    # Time distributed Softmax FC layer\n",
        "    decoder_dense_layer = keras.layers.Dense(decoder_vocab_size, activation=\"softmax\", name=\"dense_1\")\n",
        "    decoder_dense_output = decoder_dense_layer(dense_concat_input)\n",
        "\n",
        "    # Define the model that will turn encoder_input_data and decoder_input_data into decoder_target_data\n",
        "    model = keras.Model([encoder_input, decoder_input], decoder_dense_output)\n",
        "\n",
        "    model.summary(line_length=150)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f79BleNNgJTe"
      },
      "source": [
        "### Inference Model (with attention)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aBpevCUYHww"
      },
      "source": [
        "def create_attention_inference_model(model):\n",
        "    '''\n",
        "    Function to return models needed for inference from the original model (with attention).\n",
        "    Arguments :\n",
        "        model -- (Keras model object) attention model used for training\n",
        "    Returns :\n",
        "        encoder_model -- (Keras model object) \n",
        "        deocder_model -- (Keras model object)\n",
        "        no_enc_layers -- (int) number of layers in the encoder\n",
        "        no_dec_layers -- (int) number of layers in the decoder\n",
        "    '''\n",
        "    # Calculating number of layers in encoder and decoder\n",
        "    no_enc_layers, no_dec_layers = 0, 0\n",
        "    for layer in model.layers:\n",
        "        no_enc_layers += layer.name.startswith('encoder')\n",
        "        no_dec_layers += layer.name.startswith('decoder')\n",
        "\n",
        "    # Encoder input\n",
        "    encoder_input = model.input[0]      # Input_1\n",
        "    # Encoder cell final layer\n",
        "    encoder_cell = model.get_layer(\"encoder_\"+str(no_enc_layers))\n",
        "    encoder_type = encoder_cell.__class__.__name__\n",
        "    encoder_seq, *encoder_state = encoder_cell.output\n",
        "    # Encoder model\n",
        "    encoder_model = keras.Model(encoder_input, encoder_state)\n",
        "\n",
        "    # Decoder input\n",
        "    decoder_input = model.input[1]      # Input_2\n",
        "    decoder_inp_emb = model.get_layer(\"embedding_2\")(decoder_input)\n",
        "    decoder_seq = decoder_inp_emb\n",
        "    # Inputs to decoder layers' initial states\n",
        "    decoder_states, decoder_state_inputs = [], []\n",
        "    for i in range(1, no_dec_layers+1):\n",
        "        if encoder_type == 'LSTM':\n",
        "            decoder_state_input = [keras.Input(shape=(encoder_state[0].shape[1],), name=\"input_\"+str(2*i+1)), \n",
        "                                   keras.Input(shape=(encoder_state[1].shape[1],), name=\"input_\"+str(2*i+2))]\n",
        "        else:\n",
        "            decoder_state_input = [keras.Input(shape=(encoder_state[0].shape[1],), name=\"input_\"+str(i+2))]\n",
        "\n",
        "        decoder_cell = model.get_layer(\"decoder_\"+str(i))\n",
        "        decoder_seq, *decoder_state = decoder_cell(decoder_seq, initial_state=decoder_state_input)\n",
        "        decoder_states += decoder_state\n",
        "        decoder_state_inputs += decoder_state_input\n",
        "\n",
        "    # Attention layer\n",
        "    attn_out, attn_scores = model.get_layer('attention_1')([encoder_seq, decoder_seq])        # Bahdanau Attention\n",
        "    # Concat attention input and decoder output\n",
        "    dense_concat_input = keras.layers.Concatenate(axis=-1, name='concat_layer_1')([decoder_seq, attn_out])\n",
        "\n",
        "    # Softmax FC layer\n",
        "    decoder_dense = model.get_layer(\"dense_1\")\n",
        "    decoder_dense_output = decoder_dense(dense_concat_input)\n",
        "\n",
        "    # Decoder model\n",
        "    decoder_model = keras.Model(\n",
        "        [encoder_input, decoder_input] + decoder_state_inputs, [attn_scores, decoder_dense_output] + decoder_states\n",
        "    )\n",
        "\n",
        "    return encoder_model, decoder_model, no_enc_layers, no_dec_layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHO1Q-r_gOq3"
      },
      "source": [
        "### Model training (with attention)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iDn4vNlgJSp"
      },
      "source": [
        "# Sample config dictionary (contains the best model config) that will be sent to WANDB run as default configurations (for attention based models)\n",
        "config_2 = {\n",
        "    \"learning_rate\": 1e-3,                                      # Hyperparameter for updating the parameters in gradient descent\n",
        "    \"epochs\": 10,                                               # Number of epochs to train the model   \n",
        "    \"optimizer\": 'adam',                                        # Gradient descent algorithm used for the parameter updation\n",
        "    \"batch_size\": 64,                                           # Batch size used for the optimizer\n",
        "    \"loss_function\": 'categorical_crossentropy',                # Loss function used in the optimizer\n",
        "    \"architecture\": 'RNN',                                      # Type of neural network used\n",
        "    \"dataset\": \"Dakshina\",                                      # Name of dataset\n",
        "    \"inp_emb_size\": 256,                                         \n",
        "    \"no_enc_layers\": 1,                                         \n",
        "    \"no_dec_layers\": 1,                                         \n",
        "    \"hid_layer_size\": 256,                                       \n",
        "    \"dropout\" : 0.25,                                           \n",
        "    \"cell_type\": 'LSTM',\n",
        "    \"beam_width\": 5,\n",
        "    \"attention\": True\n",
        "}\n",
        "\n",
        "def seq2seq_attention(config, load_model=None, wandb_init=True):\n",
        "  '''\n",
        "  Function to load/create a model (with attention) and train it.\n",
        "  Arguments :\n",
        "    config -- (dict) configurations of parameters and hyperparameters ot be used for creating the model. if load_model is not None, this isn't necessary.\n",
        "                (the dictionary should contain the keys that are mentioned in config_1)\n",
        "    load_model -- (string, default : None) WANDB run ID of the model to train further. The configurations will be read from WANDB as well.\n",
        "    wandb_init -- (bool, default : True) whther or not WANDB run needs to be initiated (if this function is used as part of sweep alone, this would be False)\n",
        "  Returns :\n",
        "    model -- (Keras model object) trained model\n",
        "    config -- (dict) configuration dictionary\n",
        "    id -- (string) WANDB run ID used for training the model\n",
        "  '''\n",
        "  if load_model is not None:\n",
        "    api = wandb.Api()\n",
        "    prev_run = api.run('abisheks/assignment3/'+load_model)\n",
        "    prev_model_file = prev_run.file('model-best.h5').download(replace=True)\n",
        "    model = keras.models.load_model(prev_model_file.name, custom_objects={'AttentionLayer': AttentionLayer})\n",
        "    config_file = prev_run.file('config.yaml').download(replace=True)\n",
        "    with open(config_file.name, 'r') as file:\n",
        "      config_tmp = yaml.safe_load(file)\n",
        "    config = {}\n",
        "    config['attention'] = True\n",
        "    for key in ['learning_rate', 'epochs', 'optimizer', 'batch_size', 'loss_function', 'architecture', 'dataset', 'inp_emb_size', 'no_enc_layers', \\\n",
        "                'no_dec_layers', 'hid_layer_size', 'dropout', 'cell_type', 'beam_width']:\n",
        "      config[key] = config_tmp[key]['value']\n",
        "  else:\n",
        "    model = create_attention_model(len(input_char_dec), len(target_char_dec), config['inp_emb_size'], config['no_enc_layers'], \n",
        "                                   config['no_dec_layers'], config['hid_layer_size'], config['cell_type'], config['dropout'], config['dropout'])\n",
        "  \n",
        "  id = None\n",
        "  if wandb_init:\n",
        "    id = wandb.util.generate_id()\n",
        "    run = wandb.init(id = id, project=\"assignment3\", entity=\"abisheks\", reinit=True, config=config)\n",
        "    wandb.run.name = f\"ie_{config['inp_emb_size']}_ne_{config['no_enc_layers']}_de_{config['no_dec_layers']}_ct_{config['cell_type']}_dr_{config['dropout']}\"\n",
        "    wandb.run.name += f\"_da_{config['hid_layer_size']}_K_{config['beam_width']}_attn_{True}\"\n",
        "    wandb.run.save()\n",
        "    print(wandb.run.name)\n",
        "  \n",
        "  model = train_model(model, [train_enc_input,train_dec_input], train_dec_target, [val_enc_input,val_dec_input], val_dec_target, config['beam_width'],\n",
        "                      config['attention'], config['batch_size'], config['optimizer'], config['learning_rate'], config['epochs'], config['loss_function'])\n",
        "  \n",
        "  if wandb_init:\n",
        "    run.finish()\n",
        "\n",
        "  return model, config, id\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsfb7co_Zmjk"
      },
      "source": [
        "seq2seq_attention(None, 'tjs0skrr')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dubHhha3gE7J"
      },
      "source": [
        "### Sweep (models with attention)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqnAi_FNgPZ5"
      },
      "source": [
        "def attention_sweep_wrapper():\n",
        "    # Wrapper function to call the seq2seq_attention() function for sweeping with different hyperparameters\n",
        "\n",
        "    # Initialize a new wandb run\n",
        "    run = wandb.init(config=config_2, reinit=True)\n",
        "\n",
        "    # Config is a variable that holds and saves hyperparameters and inputs\n",
        "    config = wandb.config\n",
        "\n",
        "    wandb.run.name = f'ie_{config.inp_emb_size}_ne_{config.no_enc_layers}_de_{config.no_dec_layers}_ct_{config.cell_type}_dr_{config.dropout}'\n",
        "    wandb.run.name += f'_da_{config.hid_layer_size}_K_{config.beam_width}'\n",
        "    wandb.run.save()\n",
        "    print(wandb.run.name)\n",
        "\n",
        "    model, *_ = seq2seq_attention(config, wandb_init=False)\n",
        "    run.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3D-hWnWs18u5"
      },
      "source": [
        "# Hyperparameter choices to sweep \n",
        "sweep_config_2 = {\n",
        "    'name': 'RNN_Attention',\n",
        "    'method': 'bayes',                   # Possible search : grid, random, bayes\n",
        "    'metric': {\n",
        "      'name': 'val_accuracy',\n",
        "      'goal': 'maximize'   \n",
        "    },\n",
        "    'parameters': {\n",
        "        'inp_emb_size': {\n",
        "            'values': [32, 64, 256]\n",
        "        },\n",
        "        'no_enc_layers': {\n",
        "            'values': [1, 2, 3]\n",
        "        },\n",
        "        'no_dec_layers': {\n",
        "            'values': [1, 2, 3]\n",
        "        },\n",
        "        'hid_layer_size': {\n",
        "            'values': [32, 64, 256]\n",
        "        },\n",
        "        'cell_type': {\n",
        "            'values': ['RNN', 'LSTM', 'GRU']\n",
        "        },\n",
        "        'dropout' :{\n",
        "            'values': [0, 0.25, 0.4]\n",
        "        },\n",
        "        'beam_width': {\n",
        "            'values': [1, 5]\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbD9OeH-hz33"
      },
      "source": [
        "# Question 5a - sweep for attention based models\n",
        "######################### UNCOMMENT BELOW CODE TO RUN ##########################\n",
        "\n",
        "# sweep_id = wandb.sweep(sweep_config_2, entity=\"abisheks\", project=\"assignment3\")\n",
        "# wandb.agent(sweep_id, lambda : attention_sweep_wrapper())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeDBnl1gJSzl"
      },
      "source": [
        "### Test accuracy and sample input/output for best model (with attention)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeryZFPWJeHi"
      },
      "source": [
        "# Question 5b - sample inputs for attention based models\n",
        "######################### UNCOMMENT BELOW CODE TO RUN ##########################\n",
        "\n",
        "test2_acc, test2_exact_K_acc, test2_exact_acc, test2_loss, test2_true_out, \\\n",
        "test2_pred_out, test2_pred_scores, test2_attn_scores, model2 = test_model('n9rer9pl', test_enc_input, \n",
        "                                                                          test_dec_target, \n",
        "                                                                          max_decoder_seq_length, \n",
        "                                                                          target_char_enc, \n",
        "                                                                          target_char_dec, \n",
        "                                                                          True)\n",
        "\n",
        "# ---- NOTE!! random_samples is returned from the print_samples of no attention model. \n",
        "# Hence to use it run that cell before running this, or remove the argument (random 10 new samples will be generated) or initialize it\n",
        "print_samples(test_inp, test2_true_out, test2_pred_out, test2_pred_scores, random_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNFtRuhguTRW"
      },
      "source": [
        "The 10 random samples used for the outputs in report : \n",
        "\n",
        "[3026, 3263, 2995, 1568, 1946, 3602, 2528, 1203, 3612, 702]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpW-lDYaACqD"
      },
      "source": [
        "### Best model (with attention) summary plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZmyA_fn_HIF"
      },
      "source": [
        "# To visualise the best model (with attention) ------ NOTE!! Uncomment the above cell also before running this cell\n",
        "######################### UNCOMMENT BELOW CODE TO RUN ##########################\n",
        "\n",
        "plot_model(model2, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8J4yMOmoJfrD"
      },
      "source": [
        "### Attention heatmaps for best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGZD6tI1ANU2"
      },
      "source": [
        "# Downloading a font which supports English + Hindi characters to be able to caption in matplotlib using both languages\n",
        "!yes | wget -P fonts \"https://www.fontsquirrel.com/fonts/download/vesper-libre\"\n",
        "%cd fonts\n",
        "!yes | unzip vesper-libre\n",
        "!yes | mv VesperLibre-Regular.ttf /usr/share/fonts/truetype/\n",
        "%cd ../\n",
        "!fc-list :lang=hi family"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIwMyRQa9Hb4"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.font_manager import FontProperties\n",
        "\n",
        "def plot_heatmaps(input, pred_out, pred_scores, attn_scores, wandb_log=False, rand_seq=None):\n",
        "    '''\n",
        "    Function to generate attention heatmaps for 9 samples in a 3 x 3 grid\n",
        "    Arguments :\n",
        "        input -- input words\n",
        "        true_out -- true output as words\n",
        "        pred_out -- K predicted output words\n",
        "        pred_scores -- levenshtein distance for the predictions to the true output\n",
        "        attn_scores -- attention scores\n",
        "        wandb_log -- (bool, default : False) whether or not to log the image generated to WANDB\n",
        "        rand_seq -- list of indices from the dataset passed for which the sample outputs are to be printed (If None, random 9 samples will be chosen)\n",
        "                    (The length of list passed should be >= 9)\n",
        "    Returns :\n",
        "        rand_seq -- the list of indices for which sample outputs are printed\n",
        "    '''\n",
        "    no_samples = len(pred_out)\n",
        "    if rand_seq is None:\n",
        "        rand_seq = np.random.randint(no_samples, size=(9,))\n",
        "    rand_seq = rand_seq[:9]\n",
        "    \n",
        "    plt.close('all')\n",
        "    fig = plt.figure(figsize=(15,15))\n",
        "    fig, axes = plt.subplots(3, 3, figsize=(15, 15), constrained_layout=True)\n",
        "    plt.suptitle('Attention Heatmaps', fontsize='x-large')\n",
        "    for i,ax in zip(rand_seq, axes.flat):\n",
        "        K = len(pred_scores[i])\n",
        "        k = np.argmin(pred_scores[i])\n",
        "        im = ax.imshow(attn_scores[i,k,:len(pred_out[i][k])+1,:len(input[i])+1].T, vmin=0, vmax=1, cmap='magma')\n",
        "        ax.set_xticks(range(len(pred_out[i][k])+1))\n",
        "        ax.set_xticklabels(list(pred_out[i][k])+['<end>'], fontproperties=FontProperties(fname=\"/usr/share/fonts/truetype/VesperLibre-Regular.ttf\"))\n",
        "        ax.set_yticks(range(len(input[i])+1))\n",
        "        ax.set_yticklabels(list(input[i])+['<end>'])\n",
        "        ax.set_ylabel(u'Encoder Input')\n",
        "        ax.set_xlabel(f'Decoder Output')\n",
        "        ax.set_title(str(i) + r'$^{th}$ example of Test Set')\n",
        "        ax.set_aspect(\"equal\")\n",
        "        ax.grid(False)\n",
        "\n",
        "    # create colorbar\n",
        "    fig.colorbar(im, ax=axes.ravel().tolist(), shrink=0.7)\n",
        "    # Log in WANDB\n",
        "    if wandb_log:\n",
        "        run = wandb.init(project=\"assignment3\", entity=\"abisheks\", reinit=True)\n",
        "        wandb.log({'attention_heatmaps': fig})\n",
        "        run.finish()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return rand_seq\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1Rkk2BvwdXa"
      },
      "source": [
        "# Question 5d - plotting attention heatmaps\n",
        "######################### UNCOMMENT BELOW CODE TO RUN ##########################\n",
        "\n",
        "# ---- NOTE!! random_samples is returned from the print_samples of no attention model. \n",
        "# Hence to use it run that cell before running this, or remove the argument (random 10 new samples will be generated) or initialize it\n",
        "plot_heatmaps(test_inp, test2_pred_out, test2_pred_scores, test2_attn_scores, random_samples))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niOvGRJJJl1z"
      },
      "source": [
        "### Visualizing attention connectivity for best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmkOignlS2vH"
      },
      "source": [
        "def cstr(s, color=None):\n",
        "  # Function to get text html element\n",
        "  if color is None:\n",
        "      return '''<text style=\"padding:2px\"> {} </text>'''.format(s)\n",
        "  return '''<text style=\"color:#000;background-color:{};padding:2px\"> {} </text>'''.format(color, s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viuTh9l6EJjg"
      },
      "source": [
        "def print_connectivity(input, pred_out, pred_scores, attn_scores, dec_char_ind=0):\n",
        "    '''\n",
        "    Function to visualize attention for one index of decoder output of one sample\n",
        "    Arguments :\n",
        "        input -- sample input word\n",
        "        pred_out -- K predicted output words for the sample\n",
        "        pred_scores -- levenshtein distance for the predictions to the true output\n",
        "        attn_scores -- attention scores\n",
        "        dec_char_ind -- (default : 0) index of the character in decoder for which the visuzalization is to be done\n",
        "    Returns :\n",
        "        -- None --\n",
        "    '''\n",
        "    K = len(pred_scores)\n",
        "    print('-'*20 + f' Visualizing attention for Top {K} predictions (in decreasing order of probabilities) ' + '-'*20)\n",
        "    print('')\n",
        "    html_str = '''\n",
        "    <table style=\"border:2px solid black; border-collapse:collapse\">\n",
        "    <caption> <strong>INPUT : </strong> {} </caption>\n",
        "    <tr>\n",
        "    <th style=\"border:1px solid black;padding:10px;text-align:center\"> Character in Prediction Focussed </th>\n",
        "    <th style=\"border:1px solid black;padding:10px;text-align:center\"> Attention Visualization </th>\n",
        "    </tr>\n",
        "    '''.format(input)\n",
        "    for k in range(K):  \n",
        "        char = pred_out[k][dec_char_ind] if dec_char_ind < len(pred_out[k]) else '&lt end &gt' if dec_char_ind == len(pred_out[k]) else '&lt blank &gt'\n",
        "        html_str += '''\n",
        "        <tr>\n",
        "        <td style=\"border:1px solid black;padding:10px;text-align:center\"> character at index {} of {} <br/> {} </td>\n",
        "        <td style=\"border:1px solid black;padding:10px;text-align:center\">\n",
        "        '''.format(dec_char_ind, pred_out[k], char)\n",
        "        for i,c in enumerate(input):\n",
        "            html_str += '''\n",
        "            {}\n",
        "            '''.format(cstr(c, get_clr(attn_scores[k,dec_char_ind,i], 'Greens')))\n",
        "        html_str += '''\n",
        "        </td>\n",
        "        </tr>\n",
        "        '''\n",
        "    html_str += '''\n",
        "    </table>\n",
        "    '''\n",
        "    display(html_print(html_str))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h-Cw5GUGT2b"
      },
      "source": [
        "def visualize_attention(sample_ind=0, dec_char_ind=0):\n",
        "    # Function to visualize the importance of encoder input characters to the (dec_char_ind)th character of the output,\n",
        "    # for the (sample_ind)th sample in the test data\n",
        "    print_connectivity(test_inp[sample_ind], test2_pred_out[sample_ind], test2_pred_scores[sample_ind], test2_attn_scores[sample_ind], dec_char_ind)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IiZE03mJMy5"
      },
      "source": [
        "def interact():\n",
        "    # Function to interact with the user to get the sample number and index in decoder to visualize the attention\n",
        "    print(f'Enter the index of the sample (0-{len(test_inp)}) : ')\n",
        "    s_ind = int(input())\n",
        "    print(f'Input : {test_inp[s_ind]}')\n",
        "    print(f'Top {len(test2_pred_out[s_ind])} predictions : ')\n",
        "    mx_len = 0\n",
        "    for pred in test2_pred_out[s_ind]:\n",
        "        print(pred)\n",
        "        mx_len = max(mx_len, len(pred))\n",
        "    print(f'Enter the index of output character to visualize the attention for (0-{mx_len-1}): ')\n",
        "    c_ind = int(input())\n",
        "    visualize_attention(s_ind, c_ind)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGJH4ZN3cuKR"
      },
      "source": [
        "# Question 6 - visualizing attention\n",
        "######################### UNCOMMENT BELOW CODE TO RUN ##########################\n",
        "\n",
        "# One can directly use visualize_attention(sample_ind, decoder_index) to get the result if interaction isn't needed, \n",
        "# but interact() function is easier to use and offers a good way to choose the decoder index, seeing the K decoder predictons\n",
        "interact()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}