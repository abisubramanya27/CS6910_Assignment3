{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abisubramanya27/CS6910_Assignment3/blob/master/src/Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anLHOjMmcDNp",
        "outputId": "efc211b8-2c58-4358-a955-7985a023af7d"
      },
      "source": [
        "!wget \"https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-25 18:28:05--  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.81.208, 142.250.73.208, 142.250.65.80, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.81.208|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2008340480 (1.9G) [application/x-tar]\n",
            "Saving to: ‘dakshina_dataset_v1.0.tar’\n",
            "\n",
            "dakshina_dataset_v1 100%[===================>]   1.87G  22.4MB/s    in 18s     \n",
            "\n",
            "2021-04-25 18:28:23 (106 MB/s) - ‘dakshina_dataset_v1.0.tar’ saved [2008340480/2008340480]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8z7gFejcpWM"
      },
      "source": [
        "!tar xopf dakshina_dataset_v1.0.tar"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6Ixguaue_fq",
        "outputId": "54cec27a-7db2-4c8a-f7a8-30a74a4ee123"
      },
      "source": [
        "!ls dakshina_dataset_v1.0/hi/lexicons"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hi.translit.sampled.dev.tsv   hi.translit.sampled.train.tsv\n",
            "hi.translit.sampled.test.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-xkKp8jY8Q9"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def read_data(data_path, characters = False):\n",
        "    # Returns the (input, output) pair from the dataset\n",
        "    # If characters == True, the input/output would be in the form list of characters, else as string\n",
        "\n",
        "    with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        lines = [line.split(\"\\t\") for line in f.read().split(\"\\n\") if line != '']\n",
        "    \n",
        "    input, target = [val[1] for val in lines], [val[0] for val in lines]\n",
        "    if characters:\n",
        "        input, target = [list(inp_str) for inp_str in input], [list(tar_str) for tar_str in target]\n",
        "    return input, target\n",
        "\n",
        "\n",
        "def process_data(input, output, enc_timesteps, dec_timesteps, input_char_enc, target_char_enc):\n",
        "    # Returns the input and output data in a form needed by the Keras embedding layer, where each character is encoded by an integer\n",
        "\n",
        "    # ' ' -- space (equivalent to no meaningful input)\n",
        "    encoder_input = np.array([[input_char_enc[ch] for ch in string] + [input_char_enc[' ']] * (enc_timesteps - len(string)) for string in input])\n",
        "    # '\\t' -- start of sequence, '\\n' -- end of sequence\n",
        "    decoder_input = np.array([[target_char_enc['\\t']] + [target_char_enc[ch] for ch in string] + [target_char_enc['\\n']] \n",
        "                                 + [target_char_enc[' ']] * (dec_timesteps - len(string) - 2) for string in output])\n",
        "    decoder_target = np.zeros((decoder_input.shape[0], dec_timesteps, len(target_char_enc)), dtype='float32')\n",
        "\n",
        "    for i in range(decoder_input.shape[0]):\n",
        "        for t, char_ind in enumerate(decoder_input[i]):\n",
        "            if t > 0:\n",
        "                decoder_target[i,t-1,char_ind] = 1.0\n",
        "        decoder_target[i,t:,target_char_enc[' ']] = 1.0\n",
        "\n",
        "    return encoder_input, decoder_input, decoder_target\n",
        "\n",
        "\n",
        "def encode_decode_characters(train_input, train_target, valid_input, valid_target):\n",
        "    # Returns the encoder for characters to integer (as a dictionary) and decoder for integers to characters (as a list) for input and target data\n",
        "\n",
        "    input_char_enc = {}\n",
        "    input_char_dec = []\n",
        "    max_encoder_seq_length = 1\n",
        "    for string in train_input + valid_input:\n",
        "        max_encoder_seq_length = max(max_encoder_seq_length, len(string))\n",
        "        for char in string:\n",
        "            if char not in input_char_enc:\n",
        "                input_char_enc[char] = len(input_char_dec)\n",
        "                input_char_dec.append(char)\n",
        "    input_char_enc[' '] = len(input_char_dec)\n",
        "    input_char_dec.append(' ')\n",
        "\n",
        "    target_char_enc = {}\n",
        "    target_char_dec = []\n",
        "    target_char_enc['\\t'] = len(target_char_dec)\n",
        "    target_char_dec.append('\\t')\n",
        "    max_decoder_seq_length = 1\n",
        "    for string in train_target + valid_target:\n",
        "        max_decoder_seq_length = max(max_decoder_seq_length, len(string)+2)\n",
        "        for char in string:\n",
        "            if char not in target_char_enc:\n",
        "                target_char_enc[char] = len(target_char_dec)\n",
        "                target_char_dec.append(char)\n",
        "    target_char_enc['\\n'] = len(target_char_dec)\n",
        "    target_char_dec.append('\\n')\n",
        "    target_char_enc[' '] = len(target_char_dec)\n",
        "    target_char_dec.append(' ')\n",
        "\n",
        "    print(\"Number of training samples:\", len(train_input))\n",
        "    print(\"Number of validation samples:\", len(valid_input))\n",
        "    print(\"Number of unique input tokens:\", len(input_char_dec))\n",
        "    print(\"Number of unique output tokens:\", len(target_char_dec))\n",
        "    print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "    print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
        "\n",
        "    return input_char_enc, input_char_dec, target_char_enc, target_char_dec, max_encoder_seq_length, max_decoder_seq_length\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97ou-pxE9gCQ",
        "outputId": "4c5c2082-744e-4109-ae4c-36aa042cad7c"
      },
      "source": [
        "input_char_enc = {}\n",
        "input_char_dec = []\n",
        "target_char_enc = {}\n",
        "target_char_dec = []\n",
        "max_encoder_seq_length = 0\n",
        "max_decoder_seq_length = 0\n",
        "\n",
        "# Reading training and validation data\n",
        "train_inp, train_out = read_data('./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv', True)\n",
        "valid_inp, valid_out = read_data('./dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv', True)\n",
        "# Assigning encoder and decoder for input and target characters\n",
        "input_char_enc, input_char_dec, target_char_enc, target_char_dec, max_encoder_seq_length, max_decoder_seq_length = encode_decode_characters(train_inp, train_out, valid_inp, valid_out)\n",
        "\n",
        "# Assigning training and validation encoder input, decoder input, decoder output\n",
        "train_enc_input, train_dec_input, train_dec_target = process_data(train_inp, train_out, max_encoder_seq_length, max_decoder_seq_length, \n",
        "                                                                  input_char_enc, target_char_enc)\n",
        "valid_enc_input, valid_dec_input, valid_dec_target = process_data(valid_inp, valid_out, max_decoder_seq_length, max_decoder_seq_length, \n",
        "                                                                  input_char_enc, target_char_enc)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training samples: 44204\n",
            "Number of validation samples: 4358\n",
            "Number of unique input tokens: 27\n",
            "Number of unique output tokens: 66\n",
            "Max sequence length for inputs: 20\n",
            "Max sequence length for outputs: 21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8jvETu5Ga6g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11fedb04-6b91-4b17-d8a4-fcfeab3db569"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "def create_model(encoder_vocab_size, decoder_vocab_size, encoder_timesteps, decoder_timesteps,\n",
        "                 inp_emb_size=16, no_enc_layers=1, no_dec_layers=1, hid_layer_size=32, cell_type='LSTM', dropout=0, cell_activation='tanh'):\n",
        "    \n",
        "    get_cell = {\n",
        "        'RNN': keras.layers.SimpleRNN,\n",
        "        'GRU': keras.layers.GRU,\n",
        "        'LSTM': keras.layers.LSTM\n",
        "    }\n",
        "    # Encoder input and embedding\n",
        "    encoder_input = keras.layers.Input(shape=(encoder_timesteps,))\n",
        "    encoder_inp_emb = keras.layers.Embedding(encoder_vocab_size, inp_emb_size, input_length=encoder_timesteps)(encoder_input)\n",
        "\n",
        "    # Encoder cell layers\n",
        "    encoder_seq, *encoder_state = get_cell[cell_type](hid_layer_size, activation=cell_activation, return_sequences=True, return_state=True, \n",
        "                                                      recurrent_dropout=dropout, name=\"encoder_0\")(\n",
        "                                                            encoder_inp_emb\n",
        "                                                     )\n",
        "    for i in range(1, no_enc_layers):\n",
        "        encoder_seq, *encoder_state = get_cell[cell_type](hid_layer_size, activation=cell_activation, return_sequences=True, return_state=True, \n",
        "                                                          recurrent_dropout=dropout, name=\"encoder_\"+str(i))(\n",
        "                                                                encoder_seq\n",
        "                                                         )\n",
        "    \n",
        "    # Decoder input and embedding\n",
        "    decoder_input = keras.layers.Input(shape=(decoder_timesteps,))\n",
        "    decoder_inp_emb = keras.layers.Embedding(decoder_vocab_size, inp_emb_size, input_length=decoder_timesteps)(decoder_input)\n",
        "\n",
        "    # Decoder cell layers\n",
        "    decoder_seq, *_ = get_cell[cell_type](hid_layer_size, activation=cell_activation, return_sequences=True, return_state=True, \n",
        "                                          recurrent_dropout=dropout, name=\"decoder_0\")(\n",
        "                                                decoder_inp_emb, initial_state=encoder_state\n",
        "                                         )\n",
        "    for i in range(1, no_dec_layers):\n",
        "        decoder_seq, *_ = get_cell[cell_type](hid_layer_size, activation=cell_activation, return_sequences=True, return_state=True, \n",
        "                                              recurrent_dropout=dropout, name=\"decoder_\"+str(i))(\n",
        "                                                    decoder_seq, initial_state=encoder_state\n",
        "                                             )\n",
        "    \n",
        "    # Softmax FC layer\n",
        "    decoder_output = keras.layers.Dense(decoder_vocab_size, activation=\"softmax\")(\n",
        "        decoder_seq\n",
        "    )\n",
        "\n",
        "    # Define the model that will turn encoder_input_data and decoder_input_data into decoder_target_data\n",
        "    model = keras.Model([encoder_input, decoder_input], decoder_output)\n",
        "\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "model = create_model(len(input_char_dec), len(target_char_dec), max_encoder_seq_length, max_decoder_seq_length)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_19 (InputLayer)           [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_20 (InputLayer)           [(None, 21)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_18 (Embedding)        (None, 20, 16)       432         input_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_19 (Embedding)        (None, 21, 16)       1056        input_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "encoder_0 (LSTM)                [(None, 20, 32), (No 6272        embedding_18[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder_0 (LSTM)                [(None, 21, 32), (No 6272        embedding_19[0][0]               \n",
            "                                                                 encoder_0[0][1]                  \n",
            "                                                                 encoder_0[0][2]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 21, 66)       2178        decoder_0[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 16,210\n",
            "Trainable params: 16,210\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClA5ym6tw2fp"
      },
      "source": [
        "a = 'abc'\n",
        "print(len(a))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}